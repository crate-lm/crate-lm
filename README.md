<!-- <p align="center">
    <img src="./assets/digirl-logo-text.png" alt="logo" width="20%">
</p>
-->


<h3 align="center">
Improving Neuron-level Interpretability with White-box Language Models 
<br>
<b>Preprint</b>

</h3>


<p align="center">
| <a href="https://crate-lm.github.io/"><b>Website</b></a> | <a href="https://arxiv.org/abs/2410.16443"><b>Paper</b></a> |
</p>

---

Research Code for preprint "Improving Neuron-level Interpretability with White-box Language Models".

[Hao Bai*](https://jackgethome.com), [Yi Ma](https://people.eecs.berkeley.edu/~yima/)<br>
UC Berkeley, UIUC, HKU
<br>
*Work done at UC Berkeley

Content already released:
- model code

Content to be released during **December 2024**:

- Pre-training script
- Model checkpoints
- Performance evaluation script
- Interpretability evaluation script
