# ðŸ“¦ The CRATE Language Model

<p align="center">
    <img src="./assets/digirl-logo-text.png" alt="logo" width="50%">
</p>

<h3 align="center">
DigiRL: Training In-The-Wild Device-Control Agents with Autonomous Reinforcement Learning
<br>
<b>Oral @ <a href="https://icml-fm-wild.github.io/">FM Wild</a>, ICML</b>
    <br>
    <b>Neurips 2024</b>

</h3>


<p align="center">
| <a href="https://digirl-agent.github.io/"><b>Website | Demo | Results</b></a> | <a href="https://arxiv.org/abs/2406.11896"><b>Paper</b></a> | <a href="https://drive.google.com/drive/folders/14Iu6lAHePQ2qG0ghYkVG1RG6RUu7e2Hz?usp=sharing"><b>Checkpoints | Data</b></a> |
</p>

---

Research Code for preprint "DigiRL: Training In-The-Wild Device-Control Agents with Autonomous Reinforcement Learning".

[Hao Bai*](https://jackgethome.com), [Yifei Zhou*](https://<username>02.github.io/), [Mert Cemri](https://scholar.google.com/citations?user=sMEFwf8AAAAJ&hl=en), [Jiayi Pan](https://www.jiayipan.me/), [Alane Suhr](https://www.alanesuhr.com/), [Sergey Levine](https://people.eecs.berkeley.edu/~svlevine/), [Aviral Kumar](https://aviralkumar2907.github.io/)<br>
UC Berkeley, UIUC, Google DeepMind
<br>
*Equal contribution, alphabetic order; work done at UC Berkeley

<p align="center">
    <img src="./assets/digirl-diagram.png" alt="digirl-diagram" width="70%">
</p>

Official Repository of the Paper "Improving Neuron-level Interpretability with White-box Language Models". 

Content already released:
- model code

Content to be released during **December 2024**:

- Pre-training script
- Model checkpoints
- Performance evaluation script
- Interpretability evaluation script
